{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import usual libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 1 - DATA MANIPULATION\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 2 - DATA VISUALISATION\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Make all figures tiny for readability purpose\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (5,3)\n",
    "import fredpy as fp\n",
    "fp.api_key = '9d67cbd8bb040b937e856dcfb9c39856'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Test Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fred_ticker = ['MORTGAGE30US','CCLACBW027SBOG','WTISPLC','EXPINF1YR','STLPPM','M2REAL','UNRATE','PPIACO','PCUOMFGOMFG','PCUATRANSATRANS','PCUATRADEATRADE','PCUAWHLTRAWHLTR','CSUSHPINSA','SPCS20RSA',\n",
    " 'WALCL','REAINTRATREARAT10Y','SAHMREALTIME','POPTHM','CES0500000003','NFCI','WEI','ICSA','ADPWNUSNERSA', 'FEDFUNDS', 'CORESTICKM159SFRBATL','CPIAUCSL','PAYEMS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an empty DataFrame with the specified date range\n",
    "start_date = '2014-05-01'\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "df = pd.DataFrame(index=date_range)\n",
    "\n",
    "# Loop through each ticker, fetch the data, and join to the DataFrame\n",
    "for ticker in Fred_ticker:\n",
    "    series_data = fp.series(ticker)\n",
    "    df = df.join(series_data.data, how='left', rsuffix=f'_{ticker}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value_MORTGAGE30US'] = df['value']\n",
    "df = df.drop(columns='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 20 entries, 2024-03-02 to 2024-03-21\n",
      "Freq: D\n",
      "Data columns (total 27 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   value_CCLACBW027SBOG        1 non-null      float64\n",
      " 1   value_WTISPLC               0 non-null      float64\n",
      " 2   value_EXPINF1YR             0 non-null      float64\n",
      " 3   value_STLPPM                0 non-null      float64\n",
      " 4   value_M2REAL                0 non-null      float64\n",
      " 5   value_UNRATE                0 non-null      float64\n",
      " 6   value_PPIACO                0 non-null      float64\n",
      " 7   value_PCUOMFGOMFG           0 non-null      float64\n",
      " 8   value_PCUATRANSATRANS       0 non-null      float64\n",
      " 9   value_PCUATRADEATRADE       0 non-null      float64\n",
      " 10  value_PCUAWHLTRAWHLTR       0 non-null      float64\n",
      " 11  value_CSUSHPINSA            0 non-null      float64\n",
      " 12  value_SPCS20RSA             0 non-null      float64\n",
      " 13  value_WALCL                 2 non-null      float64\n",
      " 14  value_REAINTRATREARAT10Y    0 non-null      float64\n",
      " 15  value_SAHMREALTIME          0 non-null      float64\n",
      " 16  value_POPTHM                0 non-null      float64\n",
      " 17  value_CES0500000003         0 non-null      float64\n",
      " 18  value_NFCI                  2 non-null      float64\n",
      " 19  value_WEI                   2 non-null      float64\n",
      " 20  value_ICSA                  2 non-null      float64\n",
      " 21  value_ADPWNUSNERSA          0 non-null      float64\n",
      " 22  value_FEDFUNDS              0 non-null      float64\n",
      " 23  value_CORESTICKM159SFRBATL  0 non-null      float64\n",
      " 24  value_CPIAUCSL              0 non-null      float64\n",
      " 25  value_PAYEMS                0 non-null      float64\n",
      " 26  value_MORTGAGE30US          2 non-null      float64\n",
      "dtypes: float64(27)\n",
      "memory usage: 4.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.tail(20).info(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdpnow = pd.read_csv('gdpnow_daily_gdp_interp.csv', index_col='Unnamed: 0', parse_dates=True) #date_parser=dateparse)\n",
    "# Ensure that load_df index is in the same date format\n",
    "gdpnow.index = pd.to_datetime(gdpnow.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbg_mkt = pd.read_csv('data/bbg_mkt.csv',index_col='Dates', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_gdp = pd.read_csv('data/SP_GDP.csv', index_col='Unnamed: 0', parse_dates=True)\n",
    "sp_gdp = sp_gdp.drop(columns=['Unnamed: 3', 'Unnamed: 4'])\n",
    "sp_gdp = sp_gdp.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Create an empty DataFrame with the specified date range\n",
    "# start_date = '2014-05-01'\n",
    "# end_date = '2024-01-19'\n",
    "# date_range = pd.date_range(start=start_date, end=end_date)\n",
    "# adp_wei_df = pd.DataFrame(index=date_range)\n",
    "\n",
    "\n",
    "# adp = pd.read_csv('data/ADPWNUSNERSA.csv',index_col='DATE', parse_dates=True)\n",
    "# wei = pd.read_csv('data/WEI.csv',index_col='DATE', parse_dates=True)\n",
    "\n",
    "\n",
    "# # Merge the DataFrames on the index (Dates) and keep all dates\n",
    "# adp_wei_df = adp_wei_df.merge(adp, left_index=True, right_index=True, how='left')\n",
    "# adp_wei_df = adp_wei_df.merge(wei, left_index=True, right_index=True, how='left')\n",
    "\n",
    "\n",
    "# # Fill NaN values using forward fill method\n",
    "# adp_wei_df = adp_wei_df.fillna(method='ffill')\n",
    "\n",
    "# # Fill NaN values using back fill method\n",
    "# adp_wei_df = adp_wei_df.fillna(method='bfill')\n",
    "\n",
    "# adp_wei_df.index = pd.to_datetime(adp_wei_df.index)\n",
    "\n",
    "# # Renaming the index of adp_wei_df\n",
    "# adp_wei_df.index.name = 'Dates'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_df = df.merge(bbg_mkt, left_index=True, right_index=True, how='left')\n",
    "hf_df = hf_df.merge(sp_gdp, left_index=True, right_index=True, how='left')\n",
    "# hf_df = hf_df.merge(adp_wei_df, left_index=True, right_index=True, how='left')\n",
    "\n",
    "\n",
    "# Fill NaN values using forward fill method\n",
    "hf_df = hf_df.fillna(method='ffill')\n",
    "\n",
    "# Fill NaN values using back fill method\n",
    "hf_df = hf_df.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdpnow_hf = hf_df.merge(gdpnow, left_index=True, right_index=True, how='left')\n",
    "gdpnow_hf = gdpnow_hf.loc['2014-05-01':]\n",
    "gdpnow_hf.to_csv('gdpnow_hf_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Test DataFrame from Current Quarter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to add year to your dates and convert to datetime\n",
    "def preprocess_date(date_str, year='2024'):\n",
    "    # Assuming the format is like '26-Jan', add the year to make it '26-Jan-2024'\n",
    "    date_with_year = f\"{date_str}-{year}\"\n",
    "    # Now, specify the exact format to ensure correct parsing\n",
    "    return datetime.strptime(date_with_year, '%d-%b-%Y')\n",
    "\n",
    "# Assuming 'test_current_qtr' is your DataFrame after reading the CSV\n",
    "test_current_qtr = pd.read_csv('data/test_data_Mar24.csv', index_col='Forecast Date', parse_dates=False)\n",
    "\n",
    "# Apply the preprocessing to each date in the index\n",
    "test_current_qtr.index = test_current_qtr.index.map(lambda x: preprocess_date(x))\n",
    "\n",
    "# Convert the index to pandas datetime, if it's not already\n",
    "test_current_qtr.index = pd.to_datetime(test_current_qtr.index)\n",
    "\n",
    "test_current_qtr = test_current_qtr.drop(columns=['Unnamed: 36', 'Unnamed: 37', 'Unnamed: 38', 'Unnamed: 39', 'Unnamed: 40', 'Unnamed: 41'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming test_current_qtr and gdpnow are your DataFrames\n",
    "missing_in_test = set(gdpnow.columns) - set(test_current_qtr.columns)\n",
    "missing_in_gdpnow = set(test_current_qtr.columns) - set(gdpnow.columns)\n",
    "\n",
    "print(test_current_qtr.shape , gdpnow.shape)\n",
    "print(\"Columns in gdpnow but not in test_current_qtr:\", missing_in_test)\n",
    "print(\"Columns in test_current_qtr but not in gdpnow:\", missing_in_gdpnow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure the index is set to the date for both DataFrames, if necessary\n",
    "# gdpnow.set_index('date_column_name', inplace=True)  # Uncomment and replace date_column_name as necessary\n",
    "# test_current_qtr.set_index('date_column_name', inplace=True)  # Uncomment if test_current_qtr is not already indexed by date\n",
    "\n",
    "# Store the date of the final observation of the gdpnow DataFrame\n",
    "split_date = gdpnow.index[-1]\n",
    "\n",
    "# Since 'Final_GDP_Interp' is missing in test_current_qtr, add it with default 0 values\n",
    "test_current_qtr['Final_GDP_Interp'] = 0\n",
    "\n",
    "# Merge the two DataFrames by appending rows from test_current_qtr to gdpnow\n",
    "total_gdpnow_df = pd.concat([gdpnow, test_current_qtr], axis=0)\n",
    "\n",
    "# If there are any specific columns in gdpnow that are not present in test_current_qtr, and vice versa,\n",
    "# they will be filled with NaN. For 'Final_GDP_Interp', we've already filled missing values with 0.\n",
    "\n",
    "print(\"Date of the final observation in gdpnow_df (split_date):\", split_date)\n",
    "print(\"Shape of the merged DataFrame:\", total_gdpnow_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_gdpnow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_current = '2014-01-01'\n",
    "end_date_current = datetime.now().strftime('%Y-%m-%d')\n",
    "date_range = pd.date_range(start=start_date_current, end=end_date_current)\n",
    "df_current = pd.DataFrame(index=date_range)\n",
    "\n",
    "# Loop through each ticker, fetch the data, and join to the DataFrame\n",
    "for ticker in Fred_ticker:\n",
    "    series_data = fp.series(ticker)\n",
    "    df_current = df_current.join(series_data.data, how='left', rsuffix=f'_{ticker}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_current_df = df_current.merge(bbg_mkt, left_index=True, right_index=True, how='left')\n",
    "hf_current_df = hf_current_df.merge(sp_gdp, left_index=True, right_index=True, how='left')\n",
    "\n",
    "# Fill NaN values using forward fill method\n",
    "hf_current_df = hf_current_df.fillna(method='ffill')\n",
    "\n",
    "# Fill NaN values using back fill method\n",
    "hf_current_df = hf_current_df.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_current_qtr_hf = hf_current_df.merge(test_current_qtr, left_index=True, right_index=True, how='left')\n",
    "test_current_qtr_hf.index = pd.to_datetime(test_current_qtr_hf.index)\n",
    "test_current_qtr_hf = test_current_qtr_hf.loc['2024-01-19':]\n",
    "# test_current_qtr_hf.to_csv('test_current_qtr_hf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_current_qtr_hf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pd.read_csv('data/track_record.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = test_data.drop(columns=['Unnamed: 4', 'Unnamed: 8', 'Unnamed: 9',\n",
    "#        'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13',\n",
    "#        'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17',\n",
    "#        'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21',\n",
    "#        'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25',\n",
    "#        'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29',\n",
    "#        'Unnamed: 30'])\n",
    "\n",
    "# # test_data = test_data.sort_values('Release Date')\n",
    "\n",
    "# # Ensure 'Release Date' is in the correct datetime format\n",
    "# test_data['Release Date'] = pd.to_datetime(test_data['Release Date'], format='%d/%m/%Y')\n",
    "\n",
    "# # Filter 'test_data' to include only rows where 'Release Date' is between 2014-05-01 and 2024-01-19\n",
    "# test_data = test_data[(test_data['Release Date'] > '2014-05-01') & (test_data['Release Date'] < '2024-01-19')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data= test_data.sort_values('Release Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data.to_csv('data/Test_Dates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating the interim DataFrame with specific dates and values\n",
    "# specific_dates_df = pd.DataFrame({\n",
    "#     'Release Date': pd.to_datetime(['2014-05-01', '2024-01-19']),\n",
    "#     'Final_GDP_Interp': [0.11, 3.3]\n",
    "# }).set_index('Release Date')\n",
    "\n",
    "# # Ensure gdpnow index is datetime\n",
    "# gdpnow.index = pd.to_datetime(gdpnow.index)\n",
    "\n",
    "# # Merge the specific values from specific_dates_df into gdpnow\n",
    "# gdpnow = gdpnow.combine_first(specific_dates_df)\n",
    "\n",
    "# gdpnow = gdpnow.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This was correctly done\n",
    "# test_data['Release Date'] = pd.to_datetime(test_data['Release Date'], format='%d/%m/%Y')\n",
    "\n",
    "# # Proceed with the update\n",
    "# for index, row in test_data.iterrows():\n",
    "#     # Use .at for precise label-based indexing\n",
    "#     if row['Release Date'] in gdpnow.index:\n",
    "#         gdpnow.at[row['Release Date'], 'Final_GDP_Interp'] = row[\"BEA's Advance Estimate\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdpnow['Final_GDP_Interp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdpnow['Final_GDP_Interp'] = gdpnow['Final_GDP_Interp'].interpolate(method='time')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Example setup for demonstration\n",
    "# # Assuming gdpnow and test_data DataFrames are defined, like:\n",
    "# # gdpnow = pd.DataFrame({\n",
    "# #     'Date': pd.date_range(start='2014-01-01', end='2024-12-31', freq='M'),\n",
    "# #     'SomeData': np.random.rand(131)  # Just an example column\n",
    "# # }).set_index('Date')\n",
    "\n",
    "# # test_data = pd.DataFrame({\n",
    "# #     'Release Date': pd.to_datetime(['2024-01-19', '2023-10-26', '2023-07-27']),\n",
    "# #     \"BEA's Advance Estimate\": [1.1, 2.2, 3.3]\n",
    "# # })\n",
    "\n",
    "# # Step 1: Create a new column 'Final_GDP_Interp' in gdpnow as blank\n",
    "# gdpnow['Final_GDP_Interp'] = np.nan\n",
    "\n",
    "# # Step 2: Set specific value for a given date\n",
    "# gdpnow.loc['2014-05-01', 'Final_GDP_Interp'] = 0.11\n",
    "# gdpnow.loc['2014-01-19', 'Final_GDP_Interp'] = 3.3\n",
    "\n",
    "# # Step 3: Populate 'Final_GDP_Interp' with 'BEA's Advance Estimate' from test_data based on matching 'Release Date'\n",
    "# # First, ensure the 'Release Date' in test_data is in datetime format (if not already)\n",
    "# test_data['Release Date'] = pd.to_datetime(test_data['Release Date'])\n",
    "\n",
    "# # Then, iterate through test_data to update 'Final_GDP_Interp' in gdpnow\n",
    "# for index, row in test_data.iterrows():\n",
    "#     if row['Release Date'] in gdpnow.index:\n",
    "#         gdpnow.loc[row['Release Date'], 'Final_GDP_Interp'] = row[\"BEA's Advance Estimate\"]\n",
    "\n",
    "# # Step 4: Interpolate missing values in 'Final_GDP_Interp' on a time basis\n",
    "# gdpnow['Final_GDP_Interp'] = gdpnow['Final_GDP_Interp'].interpolate(method='time')\n",
    "\n",
    "# # Displaying the updated 'Final_GDP_Interp' column for verification\n",
    "# print(gdpnow['Final_GDP_Interp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # # Fill NaN values by interpolation\n",
    "# # df_interp = df.interpolate(method='time')\n",
    "# # # Export to CSV\n",
    "# gdpnow.to_csv('gdpnow_daily_gdp_interp.csv')\n",
    "# # df_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the DataFrame into test set based on the specified dates and the rest as training set\n",
    "# test_dates = ['2024-01-19', '2023-10-26', '2023-07-27', '2023-04-27',\n",
    "#                '2023-01-26', '2022-10-27', '2022-07-28', '2022-04-28',\n",
    "#                '2022-01-27', '2021-10-28', '2021-07-29', '2021-04-29',\n",
    "#                '2021-01-28', '2020-10-30', '2020-07-30', '2020-04-29',\n",
    "#                '2020-01-30', '2019-10-30', '2019-07-26', '2019-04-26',\n",
    "#                '2019-02-28', '2018-10-26', '2018-07-27', '2018-04-27',\n",
    "#                '2018-01-26', '2017-10-27', '2017-07-28', '2017-04-28',\n",
    "#                '2017-01-27', '2016-10-28', '2016-07-28', '2016-04-28',\n",
    "#                '2016-01-29', '2015-10-29', '2015-07-30', '2015-04-29',\n",
    "#                '2015-01-30', '2014-10-30', '2014-07-30', 2014-05-01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdpnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view_dates = ['2024-01-19', '2023-10-26', '2023-07-27', '2023-04-27',\n",
    "#                '2023-01-26', '2022-10-27', '2022-07-28', '2022-04-28',\n",
    "#                '2022-01-27', '2021-10-28', '2021-07-29', '2021-04-29',\n",
    "#                '2021-01-28', '2020-10-30', '2020-07-30', '2020-04-29',\n",
    "#                '2020-01-30', '2019-10-30', '2019-07-26', '2019-04-26',\n",
    "#                '2019-02-28', '2018-10-26', '2018-07-27', '2018-04-27',\n",
    "#                '2018-01-26', '2017-10-27', '2017-07-28', '2017-04-28',\n",
    "#                '2017-01-27', '2016-10-28', '2016-07-28', '2016-04-28',\n",
    "#                '2016-01-29', '2015-10-29', '2015-07-30', '2015-04-29',\n",
    "#                '2015-01-30', '2014-10-30', '2014-07-30','2014-05-01']\n",
    "# # Convert test_dates to datetime format\n",
    "# view_dates = pd.to_datetime(view_dates)\n",
    "\n",
    "# # Filter the DataFrame to show only rows where the index matches test_dates and display 'Final_GDP_Interp'\n",
    "# filtered_values = gdpnow.loc[gdpnow.index.isin(view_dates), 'Final_GDP_Interp']\n",
    "\n",
    "# filtered_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
