{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import usual libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 1 - DATA MANIPULATION\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 2 - DATA VISUALISATION\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# 4 - MACHINE LEARNING\n",
    "## 4.1 - Preprocessing\n",
    "\n",
    "### 4.1.1 - Scalers\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "### 4.1.2 - Encoders\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "### 4.1.3 - Crossvalidation, Training, Model\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "### 4.1.4 - Evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics  import ConfusionMatrixDisplay\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from math import sqrt\n",
    "\n",
    "# Make all figures tiny for readability purpose\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (5,3)\n",
    "import fredpy as fp\n",
    "fp.api_key = '9d67cbd8bb040b937e856dcfb9c39856'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "GNOW = fp.series('GDPNOW')\n",
    "\n",
    "\n",
    "# # Download CPI and GDP deflator data\n",
    "# AHE = fp.series('CES0500000003').apc()\n",
    "# deflator = fp.series('GDPDEF')\n",
    "\n",
    "# # cpi_pi = cpi_Q.apc()\n",
    "# # def_pi = deflator.apc()\n",
    "\n",
    "GNOW.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fred_ticker = ['CPIAUCSL']\n",
    "\n",
    "# already added\n",
    "# ['WTISPLC','EXPINF1YR','STLPPM','ECIWAG','M2REAL','UNRATE'] # Major Indicators\n",
    "# ['PPIACO','PCUOMFGOMFG','PCUATRANSATRANS','PCUATRADEATRADE','PCUAWHLTRAWHLTR','CSUSHPINSA','SPCS20RSA'] PPEs\n",
    "# ['WALCL', 'SP500','MEHOINUSA672N','T5YIFR','FYFSD','REAINTRATREARAT10Y','SAHMREALTIME']\n",
    "# POPTHM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an empty DataFrame with the specified date range\n",
    "start_date = '1990-01-01'\n",
    "end_date = '2024-02-29'\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "df = pd.DataFrame(index=date_range)\n",
    "\n",
    "# Loop through each ticker, fetch the data, and join to the DataFrame\n",
    "for ticker in Fred_ticker:\n",
    "    series_data = fp.series(ticker)\n",
    "    series_data.data = series_data.data.asfreq('B')  # Ensure business day frequency\n",
    "    df = df.join(series_data.data, how='left', rsuffix=f'_{ticker}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fill NaN values by interpolation\n",
    "df_interp = df.interpolate(method='time')\n",
    "# Export to CSV\n",
    "#df_interp.to_csv('FRED_data_interp.csv')\n",
    "df_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interp['CPIAUCSL'] = df_interp['value']\n",
    "df_interp.drop(columns=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.read_csv('total_df_w_fred_gdp.csv', index_col='Unnamed: 0', parse_dates=True)\n",
    "\n",
    "\n",
    "total_df.index = pd.to_datetime(total_df.index)\n",
    "\n",
    "# Merge 'df' with 'total_df' on the date index\n",
    "merged_df = df_interp.merge(total_df, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# Filter by date range, e.g., starting from '1990-01-31'\n",
    "filtered_df = merged_df.loc['1990-01-31':]\n",
    "filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.drop(columns=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the filtered DataFrame to CSV\n",
    "filtered_df.to_csv('total_df_w_fred_gdp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NFP = fp.series('PAYEMS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFP.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'cpi' is your fredpy.series object for CPI data\n",
    "# And assuming 'cpi.data' and 'cpi.dates' give you the CPI values and corresponding dates, respectively\n",
    "\n",
    "# Step 1: Create a DataFrame with CPI data\n",
    "cpi_df = pd.DataFrame({'CPI': cpi_pi.data.values}, index=cpi_pi.data.index)\n",
    "\n",
    "# The 'index=cpi.dates' part sets the DataFrame's index to the dates right upon creation.\n",
    "\n",
    "# Note: Adjust attribute names ('data' and 'dates') as per the actual structure of your fredpy.series object\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(cpi_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['inflation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cpi_df.index = us_cpi_df.index.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cpi_df = us_cpi_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_cpi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV\n",
    "us_cpi_df.to_csv('data/us_cpi.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.series(UNRATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Fetch the data\n",
    "series_id = 'CES0500000003'\n",
    "data = fp.series(series_id)\n",
    "\n",
    "# Calculate MoM percentage change\n",
    "mom_change = data.pct_change() * 100  # Convert to percentage\n",
    "\n",
    "# Display the last few rows to see recent MoM changes\n",
    "print(mom_change.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CPI and GDP deflator data\n",
    "AHE = fp.series('CES0500000003')\n",
    "\n",
    "ahe_data = pd.Series(AHE.data)\n",
    "\n",
    "\n",
    "ahe_data.tail(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(AHE.data,'-',lw=3,alpha = 0.65,label='cpi')\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title('US inflation')\n",
    "ax.set_ylabel('Percent')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdpnow = pd.read_csv('data/gdpnow_daily_df.csv', index_col='Unnamed: 0', parse_dates=True) #date_parser=dateparse)\n",
    "# Ensure that load_df index is in the same date format\n",
    "gdpnow.index = pd.to_datetime(gdpnow.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdpnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "track = pd.read_csv('data/TrackRecord.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = track.drop(columns=['Unnamed: 4', 'Unnamed: 8', 'Unnamed: 9',\n",
    "       'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13',\n",
    "       'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17',\n",
    "       'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21',\n",
    "       'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25',\n",
    "       'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29',\n",
    "       'Unnamed: 30'])\n",
    "\n",
    "# test_data = test_data.sort_values('Release Date')\n",
    "\n",
    "# Ensure 'Release Date' is in the correct datetime format\n",
    "test_data['Release Date'] = pd.to_datetime(test_data['Release Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Filter 'test_data' to include only rows where 'Release Date' is between 2014-05-01 and 2024-01-19\n",
    "test_data = test_data[(test_data['Release Date'] > '2014-05-01') & (test_data['Release Date'] < '2024-01-19')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data_sorted = test_data.sort_values('Release Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the interim DataFrame with specific dates and values\n",
    "specific_dates_df = pd.DataFrame({\n",
    "    'Release Date': pd.to_datetime(['2014-05-01', '2024-01-19']),\n",
    "    'Final_GDP_Interp': [0.11, 3.3]\n",
    "}).set_index('Release Date')\n",
    "\n",
    "# Ensure gdpnow index is datetime\n",
    "gdpnow.index = pd.to_datetime(gdpnow.index)\n",
    "\n",
    "# Merge the specific values from specific_dates_df into gdpnow\n",
    "gdpnow = gdpnow.combine_first(specific_dates_df)\n",
    "\n",
    "gdpnow = gdpnow.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was correctly done\n",
    "test_data['Release Date'] = pd.to_datetime(test_data['Release Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Proceed with the update\n",
    "for index, row in test_data.iterrows():\n",
    "    # Use .at for precise label-based indexing\n",
    "    if row['Release Date'] in gdpnow.index:\n",
    "        gdpnow.at[row['Release Date'], 'Final_GDP_Interp'] = row[\"BEA's Advance Estimate\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdpnow['Final_GDP_Interp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdpnow['Final_GDP_Interp'] = gdpnow['Final_GDP_Interp'].interpolate(method='time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example setup for demonstration\n",
    "# Assuming gdpnow and test_data DataFrames are defined, like:\n",
    "# gdpnow = pd.DataFrame({\n",
    "#     'Date': pd.date_range(start='2014-01-01', end='2024-12-31', freq='M'),\n",
    "#     'SomeData': np.random.rand(131)  # Just an example column\n",
    "# }).set_index('Date')\n",
    "\n",
    "# test_data = pd.DataFrame({\n",
    "#     'Release Date': pd.to_datetime(['2024-01-19', '2023-10-26', '2023-07-27']),\n",
    "#     \"BEA's Advance Estimate\": [1.1, 2.2, 3.3]\n",
    "# })\n",
    "\n",
    "# Step 1: Create a new column 'Final_GDP_Interp' in gdpnow as blank\n",
    "gdpnow['Final_GDP_Interp'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Set specific value for a given date\n",
    "gdpnow.loc['2014-05-01', 'Final_GDP_Interp'] = 0.11\n",
    "gdpnow.loc['2014-01-19', 'Final_GDP_Interp'] = 3.3\n",
    "\n",
    "# Step 3: Populate 'Final_GDP_Interp' with 'BEA's Advance Estimate' from test_data based on matching 'Release Date'\n",
    "# First, ensure the 'Release Date' in test_data is in datetime format (if not already)\n",
    "test_data['Release Date'] = pd.to_datetime(test_data['Release Date'])\n",
    "\n",
    "# Then, iterate through test_data to update 'Final_GDP_Interp' in gdpnow\n",
    "for index, row in test_data.iterrows():\n",
    "    if row['Release Date'] in gdpnow.index:\n",
    "        gdpnow.loc[row['Release Date'], 'Final_GDP_Interp'] = row[\"BEA's Advance Estimate\"]\n",
    "\n",
    "# Step 4: Interpolate missing values in 'Final_GDP_Interp' on a time basis\n",
    "gdpnow['Final_GDP_Interp'] = gdpnow['Final_GDP_Interp'].interpolate(method='time')\n",
    "\n",
    "# Displaying the updated 'Final_GDP_Interp' column for verification\n",
    "print(gdpnow['Final_GDP_Interp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Fill NaN values by interpolation\n",
    "# df_interp = df.interpolate(method='time')\n",
    "# # Export to CSV\n",
    "# #df_interp.to_csv('FRED_data_interp.csv')\n",
    "# df_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the DataFrame into test set based on the specified dates and the rest as training set\n",
    "# test_dates = ['2024-01-19', '2023-10-26', '2023-07-27', '2023-04-27',\n",
    "#                '2023-01-26', '2022-10-27', '2022-07-28', '2022-04-28',\n",
    "#                '2022-01-27', '2021-10-28', '2021-07-29', '2021-04-29',\n",
    "#                '2021-01-28', '2020-10-30', '2020-07-30', '2020-04-29',\n",
    "#                '2020-01-30', '2019-10-30', '2019-07-26', '2019-04-26',\n",
    "#                '2019-02-28', '2018-10-26', '2018-07-27', '2018-04-27',\n",
    "#                '2018-01-26', '2017-10-27', '2017-07-28', '2017-04-28',\n",
    "#                '2017-01-27', '2016-10-28', '2016-07-28', '2016-04-28',\n",
    "#                '2016-01-29', '2015-10-29', '2015-07-30', '2015-04-29',\n",
    "#                '2015-01-30', '2014-10-30', '2014-07-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdpnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_dates = ['2024-01-19', '2023-10-26', '2023-07-27', '2023-04-27',\n",
    "               '2023-01-26', '2022-10-27', '2022-07-28', '2022-04-28',\n",
    "               '2022-01-27', '2021-10-28', '2021-07-29', '2021-04-29',\n",
    "               '2021-01-28', '2020-10-30', '2020-07-30', '2020-04-29',\n",
    "               '2020-01-30', '2019-10-30', '2019-07-26', '2019-04-26',\n",
    "               '2019-02-28', '2018-10-26', '2018-07-27', '2018-04-27',\n",
    "               '2018-01-26', '2017-10-27', '2017-07-28', '2017-04-28',\n",
    "               '2017-01-27', '2016-10-28', '2016-07-28', '2016-04-28',\n",
    "               '2016-01-29', '2015-10-29', '2015-07-30', '2015-04-29',\n",
    "               '2015-01-30', '2014-10-30', '2014-07-30','2014-05-01']\n",
    "# Convert test_dates to datetime format\n",
    "view_dates = pd.to_datetime(view_dates)\n",
    "\n",
    "# Filter the DataFrame to show only rows where the index matches test_dates and display 'Final_GDP_Interp'\n",
    "filtered_values = gdpnow.loc[gdpnow.index.isin(view_dates), 'Final_GDP_Interp']\n",
    "\n",
    "filtered_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
